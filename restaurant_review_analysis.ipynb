{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Reviews Analysis on Yelp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import pickle\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n",
    "\n",
    "Yelp has a pretty large dataset on restaurants throughout the United States. However, we are more interested at restaurants around us and want to get insights from reviews in those restaurants. Thus, here we retrieved around 1000 restaurants near Mountain View, CA 94043 from Yelp as our dataset.\n",
    "\n",
    "We conducted a two-stage data scraping:\n",
    "\n",
    "1. Retrieving restaurant list from Yelp API\n",
    "2. Retrieving review list from web scraping\n",
    "\n",
    "### Retrieving restaurant list from Yelp API\n",
    "\n",
    "According to [Yelp API](https://www.yelp.com/developers/documentation/v3) documentation, we used endpoint of searching businesses to get restaurants list around certain location. \n",
    "\n",
    "Here we read [Yelp API Key](https://www.yelp.com/developers/v3/manage_app) from a local file named `api_key.txt` and provide functions to retrieve a restaurant list with location criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load API key from file \n",
    "with open('api_key.txt', 'r') as f:\n",
    "    api_key = f.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_info_for_business(row):\n",
    "    return {'name': row['name'], 'id': row['id'], 'review_count': int(row['review_count']), 'url': row['url']}\n",
    "\n",
    "def scrape_restaurant_list(api_key, location, max_num=1000):\n",
    "    \"\"\" Retrieve a restaurant list based on location from Yelp API\n",
    "        Args: \n",
    "            location(string): \n",
    "            max_num(integer): maximum number of restaurants to retrieve\n",
    "        Returns:\n",
    "            businesses_list(list): a restaurant list with name, id, review_count, url for each restaurant\n",
    "    \"\"\"   \n",
    "    payload = {'categories': 'restaurants', 'location': location, 'limit': 20, 'offset': 0}\n",
    "    basic_url = 'https://api.yelp.com/v3/businesses/search'\n",
    "    headers = {'Authorization': 'Bearer ' + api_key}\n",
    "    response = requests.get(basic_url, params=payload, headers=headers)\n",
    "    res_json = response.json()\n",
    "    total = res_json['total']\n",
    "    businesses_list = list(map(extract_info_for_business, res_json['businesses']))\n",
    "    while len(businesses_list) < total and len(businesses_list) < max_num:\n",
    "        time.sleep(0.3)\n",
    "        payload['offset'] = len(businesses_list)\n",
    "        response = requests.get(basic_url, params=payload, headers=headers)\n",
    "        res_json = response.json()\n",
    "        if 'businesses' not in res_json or len(list(res_json['businesses'])) == 0:\n",
    "            break\n",
    "        businesses_list.extend(list(map(extract_info_for_business ,res_json['businesses'])))\n",
    "    \n",
    "    return businesses_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, we retrieved a list of 1000 restaurants for further analysis. As shown below, each of the restaurant in the list contains following information:\n",
    "\n",
    "1. `name`: restaurant's name\n",
    "2. `id`: restaurant's id\n",
    "3. `review_count`: total number of reviews under that restaurant\n",
    "4. `url`: url linked to the restaurant's page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blist = scrape_restaurant_list(api_key, '94043')\n",
    "\n",
    "print('Total:', len(blist))\n",
    "# print('Total: 1000')\n",
    "print(blist[0])\n",
    "# print(\"{'name': \\\"The Sea by Alexander's Steakhouse\\\", 'id': 'P1eEPolk9EDGqVn1Jyncww', 'review_count': 874, 'url': 'https://www.yelp.com/biz/the-sea-by-alexanders-steakhouse-palo-alto?adjust_creative=6RD6nFOw75PxaCjeWnG24Q&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=6RD6nFOw75PxaCjeWnG24Q'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving review list from web scraping\n",
    "\n",
    "Yelp API also provides a way to retrieve reviews for a restaurant by its id. However, in practice, we found out the reviews sent back from API call are cut after a certain length. Thus, we scraped reviews manually from the web page. \n",
    "\n",
    "Here we provide a function to parse the reviews on a single page of a restaurant and store each review with its:\n",
    "\n",
    "1. `review_id`: review id\n",
    "2. `user_id`: user id\n",
    "3. `rating`: rating from 1.0 to 5.0\n",
    "4. `date`: date that the review is created\n",
    "5. `text`: content of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_page(html):\n",
    "    \"\"\" Parse the reviews on a single page of a restaurant.\n",
    "        Args:\n",
    "            html (string): String of HTML corresponding to a Yelp restaurant\n",
    "        Returns:\n",
    "            tuple(list, string): a tuple of two elements\n",
    "                first element: list of dictionaries corresponding to the extracted review information\n",
    "                second element: URL for the next page of reviews (or None if it is the last page)\n",
    "    \"\"\"\n",
    "    review_list = []\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    for review_block in soup.find_all('div', attrs={'class': 'review review--with-sidebar'}):\n",
    "        review_id = user_id = rating = date = text = None\n",
    "        if 'data-review-id' in review_block.attrs:\n",
    "            review_id = review_block['data-review-id']\n",
    "        if 'data-signup-object' in review_block.attrs and review_block['data-signup-object'].startswith('user_id:'):\n",
    "            user_id = review_block['data-signup-object'][8:]\n",
    "        rating_div = review_block.find('div', attrs={'class': 'i-stars'})\n",
    "        if 'title' in rating_div.attrs:\n",
    "            rating = float(rating_div['title'].split()[0])\n",
    "        date_span = review_block.find('span', attrs={'class': 'rating-qualifier'})\n",
    "        if date_span:\n",
    "            date = date_span.getText().strip()\n",
    "        review_content = review_block.find('div', attrs={'class': 'review-content'})\n",
    "        if review_content:\n",
    "            text = review_content.find('p').getText()\n",
    "        if review_id and user_id and rating and date and text:\n",
    "            review_list.append({\n",
    "                'review_id': review_id,\n",
    "                'user_id': user_id,\n",
    "                'rating': rating,\n",
    "                'date': date,\n",
    "                'text': text\n",
    "            })\n",
    "    next_link = None\n",
    "    next_ele = soup.find('a', attrs={'class': 'u-decoration-none next pagination-links_anchor'})\n",
    "    if next_ele and 'href' in next_ele.attrs:\n",
    "        next_link = next_ele['href']\n",
    "    return review_list, next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide another function to get all reviews from a restaurant list and store those data into `reviews.csv` for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_all_reviews(restaurants):\n",
    "    \"\"\" Scrape all reviews from a restaurant list and store them into reviews.csv\n",
    "        Args:\n",
    "            restaurants(list): a restaurant list with url for each restaurant\n",
    "    \"\"\"\n",
    "    for i, restaurant in enumerate(restaurants):\n",
    "        reviews = []\n",
    "        url = restaurant['url']\n",
    "        while url != None:\n",
    "            response = requests.get(url)\n",
    "            reviews_in_page, url = parse_page(response.content)\n",
    "            reviews.extend(reviews_in_page)\n",
    "        df = pd.DataFrame(reviews)\n",
    "        df.to_csv('reviews.csv', mode='a', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_all_reviews(blist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `reviews.csv`, each row represents a review with its id, user id, rating, date and text as stated before. Here is how our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4/30/2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0Si_T9jAoYGhcQbdkMa8iQ</td>\n",
       "      <td>Had an amazing four course dinner here! 1. Wil...</td>\n",
       "      <td>eBXvTpaU4KPf2Busy_xEZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4/4/2018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>du-a3LYobeY7FBM3nF-3Jg</td>\n",
       "      <td>A Saturday date night with my boyfriend - and ...</td>\n",
       "      <td>a-F64OPbsaI3Ab1imMyLAw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4/2/2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RKcin7_HV7ZmNUFn364DPg</td>\n",
       "      <td>Was able to get a seat at the bar at 1700 with...</td>\n",
       "      <td>YxX2NGb_gIhCn5c8ZbQL9w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4/15/2018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>zFQnFy3il8b6NwCFva6Evg</td>\n",
       "      <td>Tasting menu here is delicious! Alexander's pa...</td>\n",
       "      <td>mcG523uA11CIk8OP4ieRGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3/1/2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>H2OJVI0ZEh2h5OHyYJGT_g</td>\n",
       "      <td>One of the best fine dining restaurants I've b...</td>\n",
       "      <td>NFo1WMzgrt_1Jv_DrdQzAw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0       date rating               review_id  \\\n",
       "0          0  4/30/2018    5.0  0Si_T9jAoYGhcQbdkMa8iQ   \n",
       "1          1   4/4/2018    4.0  du-a3LYobeY7FBM3nF-3Jg   \n",
       "2          2   4/2/2018    5.0  RKcin7_HV7ZmNUFn364DPg   \n",
       "3          3  4/15/2018    4.0  zFQnFy3il8b6NwCFva6Evg   \n",
       "4          4   3/1/2018    5.0  H2OJVI0ZEh2h5OHyYJGT_g   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0  Had an amazing four course dinner here! 1. Wil...  eBXvTpaU4KPf2Busy_xEZA  \n",
       "1  A Saturday date night with my boyfriend - and ...  a-F64OPbsaI3Ab1imMyLAw  \n",
       "2  Was able to get a seat at the bar at 1700 with...  YxX2NGb_gIhCn5c8ZbQL9w  \n",
       "3  Tasting menu here is delicious! Alexander's pa...  mcG523uA11CIk8OP4ieRGQ  \n",
       "4  One of the best fine dining restaurants I've b...  NFo1WMzgrt_1Jv_DrdQzAw  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(open('reviews.csv','r'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data scraping phase, we actually noticed something interesting from Yelp's data. We retrieved around 1000 restaurants from Yelp API, but when we were retrieving reviews from restaurants, we found that a large number of restaurants don't have reviews at all. From that restaurant list, only around 250 restaurants have reviews in it.\n",
    "\n",
    "**为什么啊嘤**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Obeservations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
